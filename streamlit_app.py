"""
PDF Table Extraction Web App
PDF â†’ í˜ì´ì§€ ë¶„í•  â†’ ì´ë¯¸ì§€ â†’ GPT í…Œì´ë¸” ì¶”ì¶œ â†’ Excel ì €ì¥

[ì£¼ìš” ê¸°ëŠ¥]
1. 2ë‹¨ê³„ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤:
   - 1ë‹¨ê³„: GPTë¥¼ ì‚¬ìš©í•˜ì—¬ í…Œì´ë¸”ì´ ìˆëŠ” í˜ì´ì§€ ìë™ íƒì§€
   - 2ë‹¨ê³„: ì‚¬ìš©ìê°€ ì›í•˜ëŠ” í˜ì´ì§€ë§Œ ì„ íƒí•˜ì—¬ í…Œì´ë¸” ì¶”ì¶œ
2. ì„ íƒì  í…Œì´ë¸” ì¶”ì¶œ: ì²´í¬ë°•ìŠ¤ë¡œ ì›í•˜ëŠ” í˜ì´ì§€ë§Œ ì„ íƒ ê°€ëŠ¥

[ì„±ëŠ¥ ê°œì„  ì‚¬í•­]
1. ë³‘ë ¬ì²˜ë¦¬: ThreadPoolExecutorë¥¼ ì‚¬ìš©í•˜ì—¬ GPT API í˜¸ì¶œ ë³‘ë ¬í™” (ìµœëŒ€ 5ê°œ ë™ì‹œ ì²˜ë¦¬)
   - detect_table_pages(): í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë³‘ë ¬ ì²˜ë¦¬
   - process_jpgs_to_excel(): í…Œì´ë¸” ì¶”ì¶œ ë³‘ë ¬ ì²˜ë¦¬
2. DPI ìµœì í™”: DPI 150ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì†ë„ì™€ í’ˆì§ˆ ê· í˜•
3. ì„¸ì…˜ ìƒíƒœ ìµœì†Œí™”: í•„ìˆ˜ í•­ëª©ë§Œ ì„¸ì…˜ì— ì €ì¥í•˜ì—¬ ë©”ëª¨ë¦¬ ì˜¤ë²„í—¤ë“œ ê°ì†Œ
"""

import streamlit as st
import os
import json
import base64
import pandas as pd
import tempfile
import shutil
import platform
import subprocess
from io import BytesIO
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

from pdf2image import convert_from_path
from openai import OpenAI
from PyPDF2 import PdfReader, PdfWriter


# ======================== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ========================

def get_poppler_path():
    """Windowsì—ì„œ poppler ê²½ë¡œë¥¼ ì°¾ëŠ” í•¨ìˆ˜"""
    if platform.system() != "Windows":
        return None
    
    # 1. PATH í™˜ê²½ë³€ìˆ˜ì—ì„œ pdftoppm.exe ì°¾ê¸°
    pdftoppm_path = shutil.which("pdftoppm")
    if pdftoppm_path:
        bin_dir = os.path.dirname(pdftoppm_path)
        if os.path.exists(bin_dir):
            return bin_dir
    
    # 2. í™˜ê²½ë³€ìˆ˜ì—ì„œ poppler ê²½ë¡œ í™•ì¸
    if "POPPLER_PATH" in os.environ:
        env_path = os.environ["POPPLER_PATH"]
        if os.path.isdir(env_path):
            bin_path = os.path.join(env_path, "bin")
            if os.path.exists(bin_path):
                return bin_path
            if os.path.exists(os.path.join(env_path, "pdftoppm.exe")):
                return env_path
    
    # 3. ì¼ë°˜ì ì¸ poppler ì„¤ì¹˜ ê²½ë¡œë“¤
    possible_paths = [
        r"C:\poppler\bin",
        r"C:\poppler-24.08.0\Library\bin",
        r"C:\poppler-24.06.0\Library\bin",
        r"C:\poppler-24.02.0\Library\bin",
        r"C:\poppler-23.11.0\Library\bin",
        r"C:\poppler-23.10.0\Library\bin",
        r"C:\poppler-23.08.0\Library\bin",
        r"C:\Program Files\poppler\bin",
        r"C:\Program Files (x86)\poppler\bin",
        os.path.join(os.environ.get("LOCALAPPDATA", ""), "poppler", "bin"),
        os.path.join(os.environ.get("PROGRAMFILES", ""), "poppler", "bin"),
        os.path.join(os.environ.get("PROGRAMFILES(X86)", ""), "poppler", "bin"),
    ]
    
    # 4. C ë“œë¼ì´ë¸Œì—ì„œ poppler í´ë” ê²€ìƒ‰
    if os.path.exists("C:\\"):
        try:
            for item in os.listdir("C:\\"):
                poppler_dir = os.path.join("C:\\", item)
                if os.path.isdir(poppler_dir) and "poppler" in item.lower():
                    bin_path = os.path.join(poppler_dir, "bin")
                    if os.path.exists(bin_path):
                        possible_paths.append(bin_path)
                    lib_bin_path = os.path.join(poppler_dir, "Library", "bin")
                    if os.path.exists(lib_bin_path):
                        possible_paths.append(lib_bin_path)
        except:
            pass
    
    # 5. ê°€ëŠ¥í•œ ê²½ë¡œë“¤ í™•ì¸
    for path in possible_paths:
        if os.path.exists(path):
            pdftoppm_exe = os.path.join(path, "pdftoppm.exe")
            if os.path.exists(pdftoppm_exe):
                return path
    
    return None


# ======================== PDF ì²˜ë¦¬ í•¨ìˆ˜ ========================

def split_pdf(input_pdf_path, output_dir, chunk_size=15):
    """PDFë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• """
    os.makedirs(output_dir, exist_ok=True)
    
    reader = PdfReader(input_pdf_path)
    total_pages = len(reader.pages)
    outputs = []
    
    for i in range(0, total_pages, chunk_size):
        writer = PdfWriter()
        start = i
        end = min(i + chunk_size, total_pages)
        
        for p in range(start, end):
            writer.add_page(reader.pages[p])
        
        out_name = os.path.join(output_dir, f"chunk_{i // chunk_size + 1}.pdf")
        
        with open(out_name, "wb") as f:
            writer.write(f)
        
        outputs.append(out_name)
    
    return outputs


# ======================== GPT ë¶„ì„ í•¨ìˆ˜ ========================

def analyze_image_for_table(client, img_path):
    """ì´ë¯¸ì§€ì— í…Œì´ë¸”ì´ ìˆëŠ”ì§€ í™•ì¸"""
    with open(img_path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode()
    
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "Is there a table in this image? Answer yes or no."},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}}
                ]
            }
        ]
    )
    
    return resp.choices[0].message.content.strip().lower()


def detect_table_pages(client, pdf_path, poppler_path, status_placeholder):
    """PDFì—ì„œ í…Œì´ë¸”ì´ ìˆëŠ” í˜ì´ì§€ íƒì§€ (ë³‘ë ¬ì²˜ë¦¬)"""
    kwargs = {"dpi": 150}
    if poppler_path:
        kwargs["poppler_path"] = poppler_path
    
    pages = convert_from_path(pdf_path, **kwargs)
    detected_pages = []
    
    temp_dir = tempfile.mkdtemp()
    
    try:
        # ëª¨ë“  í˜ì´ì§€ë¥¼ ë¨¼ì € ì €ì¥
        img_paths = []
        for idx, img in enumerate(pages, start=1):
            img_path = os.path.join(temp_dir, f"tmp_page_{idx}.jpg")
            img.save(img_path, "JPEG")
            img_paths.append((idx, img_path))
        
        # ë³‘ë ¬ì²˜ë¦¬ë¡œ GPT API í˜¸ì¶œ (ìµœëŒ€ 5ê°œ ë™ì‹œ ì²˜ë¦¬)
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_page = {
                executor.submit(analyze_image_for_table, client, img_path): idx 
                for idx, img_path in img_paths
            }
            
            for future in as_completed(future_to_page):
                page_num = future_to_page[future]
                try:
                    result = future.result()
                    if "yes" in result.lower():
                        detected_pages.append(page_num)
                    
                    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                    completed = len([f for f in future_to_page if f.done()])
                    status_placeholder.info(f"ğŸ’¬ Asking GPT... ({completed}/{len(pages)} pages analyzed)")
                except Exception as e:
                    print(f"Error analyzing page {page_num}: {e}")
    
    finally:
        shutil.rmtree(temp_dir, ignore_errors=True)
    
    return sorted(detected_pages)


def save_table_pages_as_jpg(pdf_path, table_pages, output_dir, poppler_path):
    """í…Œì´ë¸” í˜ì´ì§€ë¥¼ JPGë¡œ ì €ì¥"""
    os.makedirs(output_dir, exist_ok=True)
    
    kwargs = {"dpi": 150}
    if poppler_path:
        kwargs["poppler_path"] = poppler_path
    
    pages = convert_from_path(pdf_path, **kwargs)
    base = Path(pdf_path).stem
    saved = []
    
    for page_num in table_pages:
        img = pages[page_num - 1]
        jpg_path = os.path.join(output_dir, f"{base}_page_{page_num}.jpg")
        img.save(jpg_path, "JPEG")
        saved.append(jpg_path)
    
    return saved


def extract_tables_from_image(client, image_path):
    """ì´ë¯¸ì§€ì—ì„œ í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ"""
    with open(image_path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode()
    
    prompt_message = (
        "You MUST extract three things from this image:\n"
        "1) The title text located ABOVE the table (even if it is not inside the table box).\n"
        "2) The header row of the table (the first row that describes columns).\n"
        "3) The table body.\n\n"
        "Return ONLY pure JSON in this structure:\n"
        "{\n"
        "  \"tables\": [\n"
        "    {\n"
        "      \"title\": \"...\",\n"
        "      \"header\": [\"...\", \"...\", ...],\n"
        "      \"data\": [[...], [...]]\n"
        "    }\n"
        "  ]\n"
        "}\n"
        "If the table has no explicit header row, leave 'header' as an empty list.\n"
        "If multiple lines of text exist above the table, combine them into a single title string.\n"
        "The JSON MUST NOT be inside markdown code fences. Return only raw JSON."
    )
    
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt_message},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}}
                ]
            }
        ]
    )
    
    raw = response.choices[0].message.content.strip()
    
    # ì½”ë“œë¸”ë¡ ì œê±°
    if raw.startswith("```"):
        raw = raw.replace("```json", "").replace("```", "").strip()
    
    try:
        return json.loads(raw)
    except json.JSONDecodeError:
        return {"tables": []}


def process_jpgs_to_excel(client, jpg_folder, status_placeholder):
    """JPG ì´ë¯¸ì§€ë“¤ì„ Excelë¡œ ë³€í™˜ (ë³‘ë ¬ì²˜ë¦¬)"""
    jpg_files = sorted(
        [os.path.join(jpg_folder, f) for f in os.listdir(jpg_folder) if f.lower().endswith(".jpg")]
    )
    
    if not jpg_files:
        return None
    
    total_files = len(jpg_files)
    
    # ë³‘ë ¬ì²˜ë¦¬ë¡œ GPT API í˜¸ì¶œ (ìµœëŒ€ 5ê°œ ë™ì‹œ ì²˜ë¦¬)
    all_results = []
    with ThreadPoolExecutor(max_workers=5) as executor:
        future_to_img = {
            executor.submit(extract_tables_from_image, client, img_path): img_path 
            for img_path in jpg_files
        }
        
        for future in as_completed(future_to_img):
            img_path = future_to_img[future]
            try:
                tables = future.result().get("tables", [])
                if tables:
                    all_results.append((img_path, tables))
                
                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                completed = len([f for f in future_to_img if f.done()])
                status_placeholder.info(f"ğŸ’¬ Extracting tables... ({completed}/{total_files} images processed)")
            except Exception as e:
                print(f"Error extracting from {Path(img_path).name}: {e}")
    
    # BytesIOë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ì— Excel íŒŒì¼ ìƒì„±
    output = BytesIO()
    writer = pd.ExcelWriter(output, engine="openpyxl")
    
    # ê²°ê³¼ë¥¼ íŒŒì¼ëª… ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ì—¬ Excelì— ì‘ì„±
    all_results.sort(key=lambda x: x[0])
    
    for img_path, tables in all_results:
        base = Path(img_path).stem
        
        for idx, t in enumerate(tables, start=1):
            title = t.get("title", "")
            header = t.get("header", [])
            data = t.get("data", [])
            
            final_rows = []
            
            if title:
                final_rows.append([title] + [""] * (max(len(header) - 1, 0)))
            
            if header:
                final_rows.append(header)
            
            final_rows.extend(data)
            
            df = pd.DataFrame(final_rows)
            sheet_name = f"{base}_T{idx}"[:31]
            df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)
    
    writer.close()
    output.seek(0)
    
    return output


# ======================== Streamlit UI ========================

def main():
    st.set_page_config(
        page_title="PDF Table Extractor",
        page_icon="ğŸ“Š",
        layout="wide"
    )
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (í•„ìˆ˜ í•­ëª©ë§Œ ìœ ì§€)
    if "processed" not in st.session_state:
        st.session_state.processed = False
    if "excel_data" not in st.session_state:
        st.session_state.excel_data = None
    if "save_dir" not in st.session_state:
        st.session_state.save_dir = None
    if "detection_complete" not in st.session_state:
        st.session_state.detection_complete = False
    if "selected_images" not in st.session_state:
        st.session_state.selected_images = []
    
    # íƒ€ì´í‹€
    st.title("ğŸ“Š PDF Table Extractor")
    st.markdown("**PDF â†’ í˜ì´ì§€ ë¶„í•  â†’ ì´ë¯¸ì§€ â†’ GPT í…Œì´ë¸” ì¶”ì¶œ â†’ Excel ì €ì¥**")
    st.markdown("*ì‚¬ìš© ëª¨ë¸: GPT-4o-Mini*")
    
    st.divider()
    
    # ======================== ì‚¬ì´ë“œë°” ========================
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # OpenAI API Key ì…ë ¥
        api_key = st.text_input(
            "OpenAI API Key",
            type="password",
            help="ê°œì¸ OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        st.divider()
        
        # Poppler ê²½ë¡œ ì…ë ¥ (Windows ì „ìš©)
        manual_poppler_path = None
        if platform.system() == "Windows":
            # ìë™ ê°ì§€ ì‹œë„
            auto_detected = get_poppler_path()
            
            if auto_detected:
                st.success(f"âœ… Poppler ìë™ ê°ì§€ë¨")
                st.code(auto_detected, language=None)
            else:
                st.warning("âš ï¸ Poppler ìë™ ê°ì§€ ì‹¤íŒ¨")
            
            # ìˆ˜ë™ ì…ë ¥ ì˜µì…˜
            with st.expander("ğŸ”§ Poppler ê²½ë¡œ ìˆ˜ë™ ì…ë ¥"):
                manual_poppler_path = st.text_input(
                    "Poppler bin í´ë” ê²½ë¡œ",
                    value=r"C:\poppler\poppler-23.11.0\Library\bin",
                    help="Popplerì˜ bin í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš” (pdftoppm.exeê°€ ìˆëŠ” í´ë”)"
                )
                
                if manual_poppler_path and manual_poppler_path.strip():
                    pdftoppm_exe = os.path.join(manual_poppler_path, "pdftoppm.exe")
                    if os.path.exists(pdftoppm_exe):
                        st.success("âœ… ì˜¬ë°”ë¥¸ ê²½ë¡œì…ë‹ˆë‹¤!")
                    else:
                        st.error("âŒ pdftoppm.exeë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            st.divider()
        
        # PDF ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            "ğŸ“„ PDF íŒŒì¼ ì—…ë¡œë“œ",
            type=["pdf"],
            help="í…Œì´ë¸”ì„ ì¶”ì¶œí•  PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
        )
        
        st.divider()
        
        # ì²˜ë¦¬ ì‹œì‘ ë²„íŠ¼
        start_button = st.button("ğŸš€ Start Processing", type="primary", use_container_width=True)
        
        st.divider()
        
        # Excel ë‹¤ìš´ë¡œë“œ (ì²˜ë¦¬ ì™„ë£Œ í›„ì—ë§Œ í‘œì‹œ)
        if st.session_state.processed and st.session_state.excel_data:
            st.download_button(
                label="ğŸ“¥ Download Excel",
                data=st.session_state.excel_data,
                file_name="extracted_tables.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
    
    # ======================== ë©”ì¸ í˜ì´ì§€ ========================
    
    # ì…ë ¥ ê²€ì¦
    if start_button:
        if not api_key:
            st.error("âŒ OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
            return
        
        if not uploaded_file:
            st.error("âŒ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
            return
        
        # ì´ˆê¸°í™”
        st.session_state.processed = False
        st.session_state.excel_data = None
        st.session_state.save_dir = None
        st.session_state.detection_complete = False
        st.session_state.selected_images = []
        
        # Poppler ê²½ë¡œ í™•ì¸
        # ìˆ˜ë™ ì…ë ¥ëœ ê²½ë¡œê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
        if manual_poppler_path and manual_poppler_path.strip():
            poppler_path = manual_poppler_path.strip()
        else:
            poppler_path = get_poppler_path()
        
        if platform.system() == "Windows" and not poppler_path:
            st.error(
                "âŒ Popplerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\n\n"
                "**í•´ê²° ë°©ë²•:**\n"
                "1. ì‚¬ì´ë“œë°”ì—ì„œ 'ğŸ”§ Poppler ê²½ë¡œ ìˆ˜ë™ ì…ë ¥'ì„ ì—´ì–´ ê²½ë¡œë¥¼ ì…ë ¥í•˜ê±°ë‚˜\n"
                "2. https://github.com/oschwartz10612/poppler-windows/releases ì—ì„œ ë‹¤ìš´ë¡œë“œ\n"
                "3. ì••ì¶• í•´ì œ í›„ C:\\poppler ê²½ë¡œì— ì €ì¥\n"
                "4. í™˜ê²½ë³€ìˆ˜ PATHì— C:\\poppler\\bin ì¶”ê°€"
            )
            return
        
        # pdftoppm.exe ì¡´ì¬ í™•ì¸
        if platform.system() == "Windows" and poppler_path:
            pdftoppm_exe = os.path.join(poppler_path, "pdftoppm.exe")
            if not os.path.exists(pdftoppm_exe):
                st.error(
                    f"âŒ ì˜ëª»ëœ Poppler ê²½ë¡œì…ë‹ˆë‹¤!\n\n"
                    f"ì…ë ¥ëœ ê²½ë¡œ: `{poppler_path}`\n\n"
                    f"pdftoppm.exe íŒŒì¼ì´ ì´ ê²½ë¡œì— ì—†ìŠµë‹ˆë‹¤.\n"
                    f"ì˜¬ë°”ë¥¸ bin í´ë” ê²½ë¡œë¥¼ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
                )
                return
        
        # API í‚¤ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        st.session_state.api_key = api_key
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            client = OpenAI(api_key=api_key)
        except Exception as e:
            st.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return
        
        # Progress barì™€ status box
        progress_bar = st.progress(0)
        status_box = st.empty()
        
        # save í´ë” ìƒì„± (ì˜êµ¬ ì €ì¥)
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_dir = os.path.join("save", f"session_{timestamp}")
        os.makedirs(save_dir, exist_ok=True)
        st.session_state.save_dir = save_dir
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ëŠ” PDFì™€ chunkë§Œ ì €ì¥
        with tempfile.TemporaryDirectory() as temp_dir:
            try:
                # Step 1: PDF ì €ì¥
                status_box.info("ğŸ“„ Saving uploaded PDF...")
                progress_bar.progress(0.05)
                
                pdf_path = os.path.join(temp_dir, "uploaded.pdf")
                with open(pdf_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                
                # Step 2: PDF ë¶„í• 
                status_box.info("âœ‚ï¸ Splitting PDF into chunks...")
                progress_bar.progress(0.10)
                
                chunks_dir = os.path.join(save_dir, "chunks")
                chunks = split_pdf(pdf_path, chunks_dir, chunk_size=15)
                
                # Step 3: í…Œì´ë¸” í˜ì´ì§€ íƒì§€
                status_box.info("ğŸ” Detecting table pages with GPT...")
                progress_bar.progress(0.20)
                
                # ë¡œì»¬ ë³€ìˆ˜ë¡œ ì²˜ë¦¬ (ì„¸ì…˜ ìƒíƒœ ìµœì†Œí™”)
                all_table_pages = {}
                all_jpg_files = []
                jpg_output_dir = os.path.join(save_dir, "PDF_single_page_jpg")
                
                total_chunks = len(chunks)
                
                for chunk_idx, chunk_path in enumerate(chunks, start=1):
                    # ì²­í¬ë³„ ì§„í–‰ë¥  ê³„ì‚° (20% ~ 60%)
                    chunk_progress = 0.20 + (0.40 * chunk_idx / total_chunks)
                    progress_bar.progress(chunk_progress)
                    
                    chunk_name = Path(chunk_path).name
                    status_box.info(f"ğŸ” Analyzing {chunk_name} ({chunk_idx}/{total_chunks})...")
                    
                    table_pages = detect_table_pages(client, chunk_path, poppler_path, status_box)
                    
                    if table_pages:
                        all_table_pages[chunk_name] = table_pages
                        
                        # JPG ì €ì¥ (save í´ë”ì— ì˜êµ¬ ì €ì¥)
                        status_box.info(f"ğŸ–¼ï¸ Saving table pages as JPG...")
                        saved_jpgs = save_table_pages_as_jpg(chunk_path, table_pages, jpg_output_dir, poppler_path)
                        all_jpg_files.extend(saved_jpgs)
                
                # í…Œì´ë¸” íƒì§€ ì™„ë£Œ
                if all_jpg_files:
                    progress_bar.progress(0.70)
                    status_box.success(f"âœ… Table detection completed! Found {len(all_jpg_files)} pages with tables.")
                    st.session_state.detection_complete = True
                    st.session_state.selected_images = all_jpg_files  # ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë‘ ì„ íƒ
                else:
                    progress_bar.progress(1.0)
                    status_box.warning("âš ï¸ No table pages were detected in the PDF.")
                    st.session_state.detection_complete = True
            
            except Exception as e:
                st.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                import traceback
                st.code(traceback.format_exc())
    
    # ======================== í˜ì´ì§€ ì„ íƒ UI ========================
    
    if st.session_state.detection_complete and st.session_state.save_dir and not st.session_state.processed:
        st.divider()
        save_dir = st.session_state.save_dir
        
        st.subheader("ğŸ“‹ í…Œì´ë¸” ì¶”ì¶œí•  í˜ì´ì§€ ì„ íƒ")
        st.markdown("ì¶”ì¶œí•˜ê³  ì‹¶ì€ í˜ì´ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”. ì„ íƒëœ í˜ì´ì§€ë§Œ í…Œì´ë¸” ì¶”ì¶œ ì‘ì—…ì´ ì§„í–‰ë©ë‹ˆë‹¤.")
        
        # JPG íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        jpg_output_dir = os.path.join(save_dir, "PDF_single_page_jpg")
        if os.path.exists(jpg_output_dir):
            jpg_files = sorted([
                os.path.join(jpg_output_dir, f) 
                for f in os.listdir(jpg_output_dir) 
                if f.lower().endswith('.jpg')
            ])
            
            if jpg_files:
                # ì „ì²´ ì„ íƒ/í•´ì œ ë²„íŠ¼
                col1, col2, col3 = st.columns([1, 1, 4])
                with col1:
                    if st.button("âœ… ì „ì²´ ì„ íƒ", use_container_width=True):
                        st.session_state.selected_images = jpg_files.copy()
                        st.rerun()
                with col2:
                    if st.button("âŒ ì „ì²´ í•´ì œ", use_container_width=True):
                        st.session_state.selected_images = []
                        st.rerun()
                
                st.markdown(f"**ì„ íƒëœ í˜ì´ì§€: {len(st.session_state.selected_images)}/{len(jpg_files)}**")
                st.divider()
                
                # ì´ë¯¸ì§€ ê·¸ë¦¬ë“œ í‘œì‹œ (ì²´í¬ë°•ìŠ¤ í¬í•¨)
                cols = st.columns(3)
                
                for idx, jpg_path in enumerate(jpg_files):
                    with cols[idx % 3]:
                        # ì´ë¯¸ì§€ í‘œì‹œ
                        st.image(jpg_path, caption=Path(jpg_path).name, use_container_width=True)
                        
                        # ì²´í¬ë°•ìŠ¤
                        is_selected = jpg_path in st.session_state.selected_images
                        if st.checkbox(
                            f"ì„ íƒ", 
                            value=is_selected, 
                            key=f"checkbox_{idx}_{Path(jpg_path).name}"
                        ):
                            if jpg_path not in st.session_state.selected_images:
                                st.session_state.selected_images.append(jpg_path)
                        else:
                            if jpg_path in st.session_state.selected_images:
                                st.session_state.selected_images.remove(jpg_path)
                
                st.divider()
                
                # í…Œì´ë¸” ì¶”ì¶œ ì‹œì‘ ë²„íŠ¼
                if st.session_state.selected_images:
                    if st.button(
                        f"ğŸš€ ì„ íƒí•œ {len(st.session_state.selected_images)}ê°œ í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì¶”ì¶œ", 
                        type="primary", 
                        use_container_width=True
                    ):
                        # Progress barì™€ status box
                        progress_bar = st.progress(0)
                        status_box = st.empty()
                        
                        try:
                            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì¬ì‚¬ìš©
                            api_key = st.session_state.get("api_key")
                            if not api_key:
                                st.error("âŒ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                                st.stop()
                            
                            client = OpenAI(api_key=api_key)
                            
                            # ì„ íƒëœ ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬
                            status_box.info("ğŸ“Š Extracting tables from selected pages...")
                            progress_bar.progress(0.1)
                            
                            # ì„ íƒëœ ì´ë¯¸ì§€ë¥¼ ì„ì‹œ í´ë”ì— ë³µì‚¬
                            temp_selected_dir = os.path.join(save_dir, "selected_pages")
                            os.makedirs(temp_selected_dir, exist_ok=True)
                            
                            for img_path in st.session_state.selected_images:
                                shutil.copy(img_path, temp_selected_dir)
                            
                            progress_bar.progress(0.2)
                            
                            # ì„ íƒëœ í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì¶”ì¶œ
                            excel_data = process_jpgs_to_excel(client, temp_selected_dir, status_box)
                            
                            if excel_data:
                                st.session_state.excel_data = excel_data.getvalue()
                                
                                # Excel íŒŒì¼ ì €ì¥
                                excel_path = os.path.join(save_dir, "extracted_tables.xlsx")
                                with open(excel_path, "wb") as f:
                                    f.write(st.session_state.excel_data)
                                
                                progress_bar.progress(1.0)
                                status_box.success(f"âœ… Table extraction completed! {len(st.session_state.selected_images)} pages processed.")
                                st.session_state.processed = True
                                st.rerun()
                            else:
                                progress_bar.progress(1.0)
                                status_box.warning("âš ï¸ No tables were extracted from the selected images.")
                        
                        except Exception as e:
                            st.error(f"âŒ í…Œì´ë¸” ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                            import traceback
                            st.code(traceback.format_exc())
                else:
                    st.warning("âš ï¸ ìµœì†Œ 1ê°œ ì´ìƒì˜ í˜ì´ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    # ======================== ê²°ê³¼ í‘œì‹œ ========================
    
    if st.session_state.processed and st.session_state.save_dir:
        st.divider()
        save_dir = st.session_state.save_dir
        
        # ì„ íƒëœ ì´ë¯¸ì§€ í‘œì‹œ
        st.subheader("ğŸ–¼ï¸ ì¶”ì¶œëœ í˜ì´ì§€")
        st.markdown(f"**ì´ {len(st.session_state.selected_images)}ê°œ í˜ì´ì§€**")
        
        # 3ì—´ ê·¸ë¦¬ë“œë¡œ í‘œì‹œ
        cols = st.columns(3)
        
        for idx, jpg_path in enumerate(st.session_state.selected_images):
            with cols[idx % 3]:
                st.image(jpg_path, caption=Path(jpg_path).name, use_container_width=True)
        
        # Excel ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ë©”ì¸ í˜ì´ì§€)
        if st.session_state.excel_data:
            st.divider()
            st.subheader("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (í´ë¼ìš°ë“œ í™˜ê²½ ê³ ë ¤)
            is_cloud = os.path.exists("/mount/src")  # Streamlit Cloud ê°ì§€
            
            if is_cloud:
                # í´ë¼ìš°ë“œ í™˜ê²½: ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë§Œ í‘œì‹œ
                st.download_button(
                    label="ğŸ“¥ Download Excel File",
                    data=st.session_state.excel_data,
                    file_name="extracted_tables.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary",
                    use_container_width=True
                )
            else:
                # ë¡œì»¬ í™˜ê²½: ë‹¤ìš´ë¡œë“œ + í´ë” ì—´ê¸° ë²„íŠ¼
                col1, col2 = st.columns(2)
                
                with col1:
                    st.download_button(
                        label="ğŸ“¥ Download Excel File",
                        data=st.session_state.excel_data,
                        file_name="extracted_tables.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        type="primary",
                        use_container_width=True
                    )
                
                with col2:
                    if st.session_state.save_dir and os.path.exists(st.session_state.save_dir):
                        if st.button("ğŸ“‚ Open Folder", type="secondary", use_container_width=True):
                            try:
                                if platform.system() == "Windows":
                                    os.startfile(st.session_state.save_dir)
                                elif platform.system() == "Darwin":  # macOS
                                    subprocess.Popen(["open", st.session_state.save_dir])
                                else:  # Linux
                                    subprocess.Popen(["xdg-open", st.session_state.save_dir])
                                st.success(f"âœ… í´ë”ë¥¼ ì—´ì—ˆìŠµë‹ˆë‹¤!")
                            except Exception as e:
                                st.error(f"âŒ í´ë”ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            
            # ì €ì¥ ìœ„ì¹˜ ì •ë³´
            if st.session_state.save_dir:
                st.info(f"ğŸ’¾ **ì €ì¥ ìœ„ì¹˜**: `{st.session_state.save_dir}`")
                
                with st.expander("ğŸ“ ì €ì¥ëœ íŒŒì¼ ëª©ë¡ ë³´ê¸°"):
                    # PDF ì²­í¬
                    chunks_dir = os.path.join(st.session_state.save_dir, "chunks")
                    if os.path.exists(chunks_dir):
                        chunks = [f for f in os.listdir(chunks_dir) if f.endswith('.pdf')]
                        st.markdown(f"**PDF ì²­í¬**: {len(chunks)}ê°œ")
                        for chunk in sorted(chunks):
                            st.text(f"  - {chunk}")
                    
                    # JPG ì´ë¯¸ì§€
                    jpg_dir = os.path.join(st.session_state.save_dir, "PDF_single_page_jpg")
                    if os.path.exists(jpg_dir):
                        jpgs = [f for f in os.listdir(jpg_dir) if f.endswith('.jpg')]
                        st.markdown(f"**JPG ì´ë¯¸ì§€**: {len(jpgs)}ê°œ")
                        for jpg in sorted(jpgs):
                            st.text(f"  - {jpg}")
                    
                    # Excel íŒŒì¼
                    excel_path = os.path.join(st.session_state.save_dir, "extracted_tables.xlsx")
                    if os.path.exists(excel_path):
                        st.markdown("**Excel íŒŒì¼**: extracted_tables.xlsx")


if __name__ == "__main__":
    main()

